import { AnalysisConfig, HeuristicRule, loadAnalysisConfig } from '../config/analysis';
import { LogModel } from '../models/Log';
import { env } from '../config/env';

export interface LogAnalysis {
  classification: string;
  explanation: string;
  suggestion: string;
  confidence: number;
  source: 'heuristic' | 'ai' | 'hybrid';
  tags: string[];
  processingTime: number;
}

export class LogAnalysisService {
  private config: AnalysisConfig;
  private aiProvider?: any;
  private analysisCache: Map<string, LogAnalysis> = new Map();

  constructor() {
    this.config = loadAnalysisConfig();
    this.initializeAIProvider();
  }

  private async initializeAIProvider() {
    // Pipeline H√≠brido: IA s√≥ √© inicializada se n√£o estiver em modo offline
    if (env.aiProvider === 'offline') {
      console.log('üîç Modo offline: apenas an√°lise heur√≠stica ativa');
      return;
    }

    try {
      switch (this.config.aiProvider) {
        case 'openai':
          this.aiProvider = await this.setupOpenAI();
          console.log('ü§ñ Provedor OpenAI inicializado');
          break;
        case 'anthropic':
          this.aiProvider = await this.setupAnthropic();
          console.log('ü§ñ Provedor Anthropic inicializado');
          break;
        case 'local':
          this.aiProvider = await this.setupLocalAI();
          console.log('ü§ñ Provedor Local inicializado');
          break;
        default:
          console.warn(`Provedor de IA n√£o suportado: ${this.config.aiProvider}`);
      }
    } catch (error) {
      console.error('Erro ao inicializar provedor de IA:', error);
      console.warn('üîÑ Fallback para modo offline (heur√≠sticas)');
      // N√£o altera a configura√ß√£o, apenas desabilita a IA para esta inst√¢ncia
    }
  }

  private async setupOpenAI() {
    if (!this.config.aiApiKey) throw new Error('OpenAI API key n√£o configurada');
    
    // Simula√ß√£o - em produ√ß√£o usar OpenAI SDK
    return {
      analyze: async (message: string, context: any) => {
        // Simula√ß√£o de an√°lise OpenAI
        await new Promise(resolve => setTimeout(resolve, 100));
        return {
          classification: 'AI Analysis',
          explanation: 'An√°lise baseada em IA OpenAI',
          suggestion: 'Sugest√£o personalizada da IA',
          confidence: 0.85,
          tags: ['ai', 'openai']
        };
      }
    };
  }

  private async setupAnthropic() {
    if (!this.config.aiApiKey) throw new Error('Anthropic API key n√£o configurada');
    
    return {
      analyze: async (message: string, context: any) => {
        await new Promise(resolve => setTimeout(resolve, 150));
        return {
          classification: 'AI Analysis',
          explanation: 'An√°lise baseada em IA Anthropic',
          suggestion: 'Sugest√£o personalizada da IA',
          confidence: 0.88,
          tags: ['ai', 'anthropic']
        };
      }
    };
  }

  private async setupLocalAI() {
    // Simula√ß√£o de IA local (poderia ser um modelo TensorFlow.js ou similar)
    return {
      analyze: async (message: string, context: any) => {
        await new Promise(resolve => setTimeout(resolve, 50));
        return {
          classification: 'Local AI Analysis',
          explanation: 'An√°lise baseada em modelo local',
          suggestion: 'Sugest√£o do modelo local',
          confidence: 0.75,
          tags: ['ai', 'local']
        };
      }
    };
  }

  public async analyzeLog(logId: string, message: string, context: any): Promise<LogAnalysis> {
    const startTime = Date.now();
    
    // Verifica cache primeiro
    const cacheKey = `${logId}_${message.substring(0, 100)}`;
    const cached = this.analysisCache.get(cacheKey);
    if (cached && Date.now() - startTime < this.config.analysisCacheTTL * 1000) {
      return cached;
    }

    let analysis: LogAnalysis;

    try {
      // Pipeline H√≠brido: Heur√≠sticas sempre rodam, IA √© condicional
      if (env.aiProvider === 'offline') {
        // Modo offline: apenas heur√≠sticas
        analysis = await this.analyzeWithHeuristics(message, context);
      } else if (env.aiProvider === 'ai-only') {
        // Modo IA apenas: requer provedor dispon√≠vel
        if (!this.aiProvider) {
          throw new Error('Provedor de IA n√£o dispon√≠vel para modo ai-only');
        }
        analysis = await this.analyzeWithAI(message, context);
      } else if (env.aiProvider === 'hybrid') {
        // Modo h√≠brido: combina heur√≠sticas + IA
        analysis = await this.analyzeHybrid(message, context);
      } else {
        // Fallback para offline se configura√ß√£o inv√°lida
        console.warn(`Configura√ß√£o AI_PROVIDER inv√°lida: ${env.aiProvider}, usando modo offline`);
        analysis = await this.analyzeWithHeuristics(message, context);
      }

      analysis.processingTime = Date.now() - startTime;
      
      // Atualiza cache
      this.analysisCache.set(cacheKey, analysis);
      
      // Atualiza o log no banco com a an√°lise
      await this.updateLogWithAnalysis(logId, analysis);
      
      return analysis;
      
    } catch (error) {
      console.error('Erro na an√°lise do log:', error);
      
      // Fallback para heur√≠sticas em caso de erro
      analysis = await this.analyzeWithHeuristics(message, context);
      analysis.source = 'heuristic';
      analysis.processingTime = Date.now() - startTime;
      
      return analysis;
    }
  }

  private async analyzeWithHeuristics(message: string, context: any): Promise<LogAnalysis> {
    const matchedRules: HeuristicRule[] = [];
    
    // Aplica todas as regras heur√≠sticas
    for (const rule of this.config.heuristicRules) {
      const pattern = typeof rule.pattern === 'string' 
        ? new RegExp(rule.pattern, 'i') 
        : rule.pattern;
      
      if (pattern.test(message)) {
        matchedRules.push(rule);
      }
    }

    if (matchedRules.length === 0) {
      return {
        classification: 'Unclassified',
        explanation: 'Log n√£o corresponde a padr√µes conhecidos',
        suggestion: 'Revisar manualmente se necess√°rio',
        confidence: 0.3,
        source: 'heuristic',
        tags: ['unclassified'],
        processingTime: 0
      };
    }

    // Ordena por prioridade e pega a melhor regra
    matchedRules.sort((a, b) => a.priority - b.priority);
    const bestRule = matchedRules[0];

    if (!bestRule) {
      return {
        classification: 'Unclassified',
        explanation: 'Nenhuma regra heur√≠stica correspondeu ao log',
        suggestion: 'Revisar manualmente se necess√°rio',
        confidence: 0.3,
        source: 'heuristic',
        tags: ['unclassified'],
        processingTime: 0
      };
    }

    return {
      classification: bestRule.classification,
      explanation: bestRule.explanation,
      suggestion: bestRule.suggestion,
      confidence: 0.7 + (matchedRules.length * 0.1), // Mais regras = mais confian√ßa
      source: 'heuristic',
      tags: bestRule.tags,
      processingTime: 0
    };
  }

  private async analyzeWithAI(message: string, context: any): Promise<LogAnalysis> {
    if (!this.aiProvider) {
      throw new Error('Provedor de IA n√£o dispon√≠vel');
    }

    const aiResult = await this.aiProvider.analyze(message, context);
    
    return {
      ...aiResult,
      source: 'ai',
      processingTime: 0
    };
  }

  private async analyzeHybrid(message: string, context: any): Promise<LogAnalysis> {
    // Pipeline H√≠brido: Heur√≠sticas sempre rodam primeiro
    const heuristicResult = await this.analyzeWithHeuristics(message, context);
    
    // IA √© acionada condicionalmente baseada na confian√ßa das heur√≠sticas
    if (heuristicResult.confidence < 0.7 && this.aiProvider) {
      try {
        console.log('ü§ñ Modo h√≠brido: acionando IA para melhorar an√°lise');
        const aiResult = await this.analyzeWithAI(message, context);
        
        // Combina resultados (heur√≠sticas + IA) com pesos inteligentes
        const combinedConfidence = Math.min(0.95, 
          (heuristicResult.confidence * 0.4) + (aiResult.confidence * 0.6)
        );
        
        return {
          classification: aiResult.classification || heuristicResult.classification,
          explanation: `Heur√≠sticas: ${heuristicResult.explanation} | IA: ${aiResult.explanation}`,
          suggestion: aiResult.suggestion || heuristicResult.suggestion,
          confidence: combinedConfidence,
          source: 'hybrid',
          tags: [...new Set([...heuristicResult.tags, ...aiResult.tags])],
          processingTime: 0
        };
      } catch (error) {
        console.warn('üîÑ IA falhou no modo h√≠brido, usando apenas heur√≠sticas:', error);
        // Fallback gracioso para heur√≠sticas
        return {
          ...heuristicResult,
          source: 'heuristic',
          tags: [...heuristicResult.tags, 'ai-fallback']
        };
      }
    }
    
    // Se heur√≠sticas t√™m alta confian√ßa, retorna direto
    return {
      ...heuristicResult,
      source: 'heuristic',
      tags: [...heuristicResult.tags, 'high-confidence']
    };
  }

  private async updateLogWithAnalysis(logId: string, analysis: LogAnalysis): Promise<void> {
    try {
      await LogModel.findByIdAndUpdate(logId, {
        'ai.classification': analysis.classification,
        'ai.explanation': analysis.explanation,
        'ai.suggestion': analysis.suggestion,
        'ai.provider': analysis.source === 'ai' ? this.config.aiProvider : 'heuristic',
        tags: analysis.tags
      });
    } catch (error) {
      console.error('Erro ao atualizar log com an√°lise:', error);
    }
  }

  public getConfig(): AnalysisConfig {
    return { ...this.config };
  }

  public updateConfig(newConfig: Partial<AnalysisConfig>): void {
    this.config = { ...this.config, ...newConfig };
    this.initializeAIProvider();
  }

  public clearCache(): void {
    this.analysisCache.clear();
  }

  public getCacheStats(): { size: number; hitRate: number } {
    return {
      size: this.analysisCache.size,
      hitRate: 0.8 // Simula√ß√£o - em produ√ß√£o calcular hit rate real
    };
  }
}

